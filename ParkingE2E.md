# ParkingE2E

### æ•´ä½“ç»“æ„

```
self.lss_bev_model = LssBevModel(self.cfg)      # LssBevModel.init() è¾“å‡ºå¤šä¸ªç›¸æœºå›¾åƒèåˆåçš„ç‰¹å¾.ä½å±‚æ¬¡çš„ BEV ç‰¹å¾ï¼Œå› ä¸ºå®ƒä¸»è¦èšç„¦åœ¨ä»å›¾åƒ â†’ BEV ç©ºé—´çš„å‡ ä½•æ˜ å°„å’Œå¯¹é½ï¼Œä¸æ¶‰åŠå¤ªå¤š BEV ç©ºé—´ä¸­çš„ä¸Šä¸‹æ–‡è¯­ä¹‰å»ºæ¨¡ã€‚
        self.image_res_encoder = BevEncoder(in_channel=self.cfg.bev_encoder_in_channel) #å¯¹ BEV å›¾åƒç‰¹å¾æå–é«˜å±‚è¯­ä¹‰ç‰¹å¾ å¤šé€šé“

        # Target Encoder
        self.target_res_encoder = BevEncoder(in_channel=1) #å˜æˆä¸€å¼ å…·æœ‰ç©ºé—´è¯­ä¹‰ä¿¡æ¯çš„å¤šé€šé“ç›®æ ‡ç‰¹å¾å›¾  è¿™ä¸ª BEV çƒ­ç‚¹å›¾æœ¬èº«åªæ˜¯ä¸ªç¨€ç–çš„ç‚¹ï¼ˆåƒç´ ä¸Šåªæœ‰ä¸€å°å—æ˜¯éé›¶çš„ï¼‰ï¼Œå¤ªåŸå§‹äº†ï¼Œä¸è¶³ä»¥æä¾›ä¸°å¯Œçš„ç©ºé—´è¯­ä¹‰ä¿¡æ¯ã€‚

        # BEV Query
        self.bev_query = BevQuery(self.cfg) #å°†ä¸¤ä¸ª BEV ç‰¹å¾è¿›è¡Œ Transformer èåˆï¼Œå¼ºè°ƒç›®æ ‡ç‚¹åŒºåŸŸ å®ƒçš„æ ¸å¿ƒæœºåˆ¶å°±æ˜¯ä¸€ä¸ª Transformer Decoder ,cross-attention

        # Trajectory Decoder
        self.trajectory_decoder = self.get_trajectory_decoder() # é¢„æµ‹ token
```
# LSS

```
self.lss_bev_model(images, intrinsics, extrinsics)
        â†“
__call__(...)  # nn.Module è‡ªåŠ¨å®šä¹‰
        â†“
forward(images, intrinsics, extrinsics)
        â†“
calc_bev_feature(images, intrinsics, extrinsics)
        â”œâ”€â”€ get_geometry(...)       â† åˆ©ç”¨ç›¸æœºå†…å¤–å‚å’Œ frustum è·å–ä¸‰ç»´åæ ‡
        â”œâ”€â”€ encoder_forward(...)    â† EfficientNetå°†å›¾åƒç¼–ç ä¸ºç‰¹å¾ + æ·±åº¦ï¼ˆlift:**çœŸæ­£è·å–æ·±åº¦**ï¼‰
        â””â”€â”€ proj_bev_feature(...)   â† å°†å›¾åƒç‰¹å¾æŠ•å½±åˆ° BEV ç©ºé—´ï¼ˆsplat:**æŠŠç‰¹å¾æ’’åˆ° BEV å¹³é¢**ï¼‰
        â†“
return bev_feature, pred_depth
```

#### åŠŸèƒ½

æ˜¾å¼åœ°ç¼–ç äº†åƒç´ ->ç©ºé—´çš„æ˜ å°„å…³ç³»ï¼ŒåŠ é€Ÿè®­ç»ƒæ”¶æ•›

**bev_camera, pred_depth = self.lss_bev_model(images, intrinsics, extrinsics)**  #bevè¯­ä¹‰ç‰¹å¾å›¾ æ¯ä¸ªæ·±åº¦å±‚çš„æ¦‚ç‡åˆ†å¸ƒ

**å†…éƒ¨ï¼š**

1.ä½¿ç”¨ `EfficientNet` æå–æ¯ä¸ªç›¸æœºå›¾åƒçš„è¯­ä¹‰ç‰¹å¾å’Œï¼ˆå¦‚æœå¯ç”¨ï¼‰åƒç´ çº§æ·±åº¦åˆ†å¸ƒï¼š

2.ä½¿ç”¨ `create_frustum()` å¾—åˆ°å›¾åƒç©ºé—´ä¸­çš„ 3D é‡‡æ ·ç½‘æ ¼ï¼ˆu, v, dï¼‰ï¼Œå³ä¸ºæ¯ä¸ªåƒç´ é‡‡æ ·å¤šä¸ªæ·±åº¦å±‚ã€‚

3.å°†æ¯ä¸ªåƒç´ ç‚¹ + æ·±åº¦ç‚¹æŠ•å½±åˆ°ä¸–ç•Œåæ ‡ç³»ä¸‹çš„ 3D ç‚¹åæ ‡ï¼ˆé€šè¿‡ `intrinsics`ã€`extrinsics`ï¼‰

4.å¤šä¸ªç›¸æœºçš„æ‰€æœ‰æ·±åº¦å±‚ä¸Šæ¯ä¸ªåƒç´ ä½ç½®å¯¹åº”çš„ç‰¹å¾ `x_b` è¢«æŠ•å½±åˆ° BEV ç½‘æ ¼ä¸­ã€‚ç›¸åŒ BEV ç½‘æ ¼ï¼ˆx, yï¼‰ä¸Šå¤šä¸ªç›¸æœº / å¤šä¸ªæ·±åº¦å±‚è½ä¸‹æ¥çš„ç‰¹å¾ä¼š **èšåˆï¼ˆæ±‚å’Œï¼‰**

### å…·ä½“ï¼šLssBevModel

self.frustum = self.create_frustum() # åˆ›å»ºè§†é”¥ä½“

self.cam_encoder = CamEncoder(self.cfg, self.depth_channel)  #è£å‡EfficientNetB0

# Encoder

## Image Encoder

bev_camera_encoder = self.image_res_encoder(bev_camera, flatten=False) 

### BEV encoder

å°±æ˜¯ç»è¿‡äº†resnet18

```
trunk = resnet18(weights=None, zero_init_residual=True)

self.conv1 = nn.Conv2d(in_channel, 64, kernel_size=7, stride=2, padding=3, bias=False)
self.bn1 = trunk.bn1
self.relu = trunk.relu
self.max_pool = trunk.maxpool

self.layer1 = trunk.layer1
self.layer2 = trunk.layer2
self.layer3 = trunk.layer3
self.layer4 = trunk.layer4
```


## ä¸ºä»€ä¹ˆç”¨Efficientnet

**å¤§å°ï¼š**

1.**EfficientNet** ç”¨äº† **MBConv + SE + Swish** ç­‰ç»“æ„ï¼Œåœ¨**åŒç­‰ç²¾åº¦ä¸‹è®¡ç®—é‡æ›´ä½**ï¼ŒåŒæ—¶ä¿ç•™è¾ƒå¼ºçš„æ„Ÿå—é‡ä¸ç‰¹å¾è¡¨è¾¾èƒ½åŠ›

2.LSS æ˜¯ä¸€ä¸ª**å¤šç›¸æœºè¾“å…¥ã€å¤šå°ºåº¦æ¨ç†**çš„ç»“æ„ï¼ˆ6~8 è·¯ç›¸æœºï¼‰ï¼Œå¦‚æœ backbone å¤ªé‡ï¼ˆå¦‚ ResNet101ï¼‰ï¼ŒGPU æ˜¾å­˜å’Œå»¶è¿Ÿéƒ½ä¼šç‚¸æ‰

**åŠŸèƒ½**ï¼š

3.æŠ‘åˆ¶æ— ç”¨é€šé“ï¼Œå¼ºåŒ–å…³é”®ä¿¡å·

- MBConv + SE ä¼šè®©ç½‘ç»œæ›´å…³æ³¨æœ‰ç”¨é€šé“ï¼Œå°ç›®æ ‡ã€è¿œè·çº¹ç†ç»†èŠ‚ä¼šä¿ç•™æ›´å¤šã€‚MBConv ç”Ÿæˆäº†å¾ˆå¤šç§é€šé“ç‰¹å¾ï¼ŒSE è®©ç½‘ç»œèƒ½**æ ¹æ®å½“å‰å›¾ç‰‡çš„æ•´ä½“ç‰¹å¾åˆ†å¸ƒ**ï¼ŒåŠ¨æ€é€‰æ‹©æœ€æœ‰ç”¨çš„é‚£å‡ ä¸ªé€šé“æ¥çªå‡º
- è¿™å¯¹ LSS ç‰¹åˆ«é‡è¦ï¼Œå› ä¸ºè¿œå¤„ç›®æ ‡åœ¨å›¾åƒé‡Œåªæœ‰å‡ åƒç´ å¤§ï¼Œç‰¹å¾ç¨å¾®è¢«å¹³æ»‘æ‰å°±æ— æ³•åœ¨ BEV ç©ºé—´è¿˜åŸ

---



### EfficientNet

**1.å‡ç»´ Expansionï¼š**

1Ã—1 Convï¼ˆæ‰©å±•ï¼‰: Cin â†’ Cin Ã— t =Cexp

```
nn.Conv2d(16, 96, kernel_size=1, bias=False),
```

**æå‡ç‰¹å¾ç»´åº¦ï¼š**æä¾›æ›´å¤šä¸­é—´ç‰¹å¾ç»„åˆï¼Œå¢åŠ è¡¨è¾¾èƒ½åŠ›ã€‚

**å¢å¼º depthwise å·ç§¯æ•ˆæœï¼š **depthwise ä¸å¤„ç†é€šé“é—´ä¿¡æ¯ï¼Œæ‰©å±•åèƒ½å¤„ç†æ›´ç»†è‡´çš„å±€éƒ¨ç©ºé—´ç‰¹å¾

â€‹		â”‚
â€‹       â–¼

ï¼ˆBatchNorm + Swishï¼‰

```
nn.BatchNorm2d(96)
nn.SiLU()
```

â€‹       â”‚

â€‹       â–¼

2.**æ·±åº¦å¯åˆ†ç¦»å·ç§¯ï¼š**

æ¯ä¸ªé€šé“å•ç‹¬ä½¿ç”¨ä¸€ä¸ªå·ç§¯æ ¸è¿›è¡Œå·ç§¯ï¼Œ**å¤§å¤§å‡å°‘å‚æ•°é‡å’Œè®¡ç®—é‡**ã€‚

â€‹		â”‚
â€‹       â–¼

ï¼ˆBatchNorm + Swishï¼‰

â€‹       â”‚

â€‹       â–¼

3.**SE æ¨¡å—ï¼ˆSqueeze-and-Excitationï¼‰**ï¼š

æç‚¼ + é™ä½å‚æ•°é‡ & è®¡ç®—é‡ ( 16 * 16-> 4 * 16 * 2)

â€‹			**Squeezeï¼ˆå‹ç¼©ï¼‰**ï¼šå…¨å±€å¹³å‡æ± åŒ–ï¼Œå¯¹æ¯ä¸ªé€šé“å‹ç¼©æˆä¸€ä¸ªæ ‡é‡

â€‹			**Excitationï¼ˆæ¿€åŠ±ï¼‰**ï¼šé€šè¿‡ä¸€ä¸ªä¸¤å±‚ MLP ç”Ÿæˆæ¯ä¸ªé€šé“çš„æƒé‡

â€‹			**Scaleï¼ˆé‡æ ‡å®šï¼‰**ï¼šç”¨è¿™äº›æƒé‡ä¹˜ä»¥åŸç‰¹å¾å›¾ï¼Œå®ç°é€šé“æ³¨æ„åŠ›

**ç”¨ `Sigmoid` çš„è¾“å‡ºï¼ˆé€šé“æ³¨æ„åŠ›æƒé‡ï¼‰å»â€œç¼©æ”¾â€è¾“å…¥ç‰¹å¾å›¾çš„æ¯ä¸€ä¸ªé€šé“**ã€‚

```
class SEModule(nn.Module):
    def __init__(self, channels, reduction=4):
        super().__init__()
        self.pool = nn.AdaptiveAvgPool2d(1)  # è¾“å‡º (B, C, 1, 1)
        self.fc1 = nn.Linear(channels, channels // reduction, bias=True) 16->4
        self.fc2 = nn.Linear(channels // reduction, channels, bias=True) 4->16
        self.relu = nn.ReLU()
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        b, c, _, _ = x.shape
        y = self.pool(x).view(b, c)           # (B, 16)
        y = self.relu(self.fc1(y))            # (B, 4)
        y = self.sigmoid(self.fc2(y))         # (B, 16)
        y = y.view(b, c, 1, 1)                # (B, C, 1, 1)
        return x * y                          # âœ… â† å…³é”®ï¼šx * attentionï¼ˆé€šé“åŠ æƒï¼‰
```

**4.Project**

````
nn.Conv2d(96, 24, kernel_size=1, bias=False),
nn.BatchNorm2d(24)
````

**5.Residual**

ä¿ç•™åŸä¿¡æ¯ï¼Œæå‡æ¢¯åº¦æµåŠ¨

## Trainer

è®¾ç½®è®­ç»ƒå™¨ Trainerï¼ŒåŒ…æ‹¬è®¾å¤‡ã€åˆ†å¸ƒå¼ç­–ç•¥ã€æ—¥å¿—è®°å½•ã€å›è°ƒã€éªŒè¯é¢‘ç‡ç­‰

```
def train(config_obj):
    parking_trainer = Trainer(callbacks=setup_callbacks(config_obj),
                              logger=TensorBoardLogger(save_dir=config_obj.log_dir, default_hp_metric=False),
                              accelerator='gpu',
                              strategy='ddp' if config_obj.num_gpus > 1 else None,
                              devices=config_obj.num_gpus,
                              max_epochs=config_obj.epochs,
                              log_every_n_steps=config_obj.log_every_n_steps,
                              check_val_every_n_epoch=config_obj.check_val_every_n_epoch,
                              profiler='simple')#è®¾ç½®è®­ç»ƒå™¨ Trainerï¼ŒåŒ…æ‹¬è®¾å¤‡ã€åˆ†å¸ƒå¼ç­–ç•¥ã€æ—¥å¿—è®°å½•ã€å›è°ƒã€éªŒè¯é¢‘ç‡ç­‰ï¼›
   
```

å®šä¹‰æ¨¡å‹

```
model = ParkingTrainingModelModule(config_obj) # å®ä¾‹åŒ–æ¨¡å‹å¯¹è±¡  
```

åŠ è½½æ•°æ®

```
data = ParkingDataloaderModule(config_obj)
```



## è‡ªåŠ¨è°ƒç”¨

ä¸‹é¢è¿™å‡ ä¸ªæ–¹æ³•æ˜¯ PyTorch Lightning åœ¨ `Trainer.fit(â€¦)`ï¼`.validate(â€¦)` æµç¨‹ä¸­**è‡ªåŠ¨**è°ƒç”¨çš„é’©å­ï¼ˆhookï¼‰æ–¹æ³•ï¼š

**pl.LightningModuleï¼ˆParkingTrainingModuleRealï¼‰**

- **`__init__`**
   å½“ä½ æ‰§è¡Œ `model = ParkingTrainingModuleReal(cfg)` æ—¶ï¼ŒPython ä¼šè°ƒç”¨å®ƒæ¥æ„é€ å¯¹è±¡ã€‚
   Lightning å¹¶ä¸ä¼šåœ¨è¿è¡Œæ—¶å†é¢å¤–è°ƒç”¨å®ƒã€‚
- **`configure_optimizers(self)`**
   åœ¨ `Trainer.fit()` ä¸€å¼€å§‹çš„æ—¶å€™ï¼ŒLightning ä¼šè°ƒç”¨å®ƒæ¥ä»ä½ çš„æ¨¡å—é‡Œæ‹¿åˆ°ï¼š
  1. ä¼˜åŒ–å™¨ï¼ˆ`optimizer`ï¼‰
  2. å­¦ä¹ ç‡è°ƒåº¦å™¨ï¼ˆ`lr_scheduler`ï¼Œå¦‚æœä½ è¿”å›çš„è¯ï¼‰
- **`training_step(self, batch, batch_idx)`**
   åœ¨æ¯ä¸ªè®­ç»ƒ epoch ä¸­ï¼Œå¯¹æ¯ä¸ªæ‹¿åˆ°çš„è®­ç»ƒ batchï¼ŒLightning ä¼šè‡ªåŠ¨è°ƒç”¨è¿™ä¸ªæ–¹æ³•ä¸€æ¬¡ã€‚
   ä½ åœ¨è¿™é‡Œå®ç°äº†å‰å‘è®¡ç®—ã€loss è®¡ç®—ã€`self.log_dict({...})` å’Œè¿”å› lossã€‚
- **`validation_step(self, batch, batch_idx)`**
   åœ¨æ¯ä¸ªéªŒè¯ epoch ä¸­ï¼Œå¯¹æ¯ä¸ªæ‹¿åˆ°çš„éªŒè¯ batchï¼ŒLightning ä¼šè‡ªåŠ¨è°ƒç”¨è¿™ä¸ªæ–¹æ³•ä¸€æ¬¡ã€‚
   ä½ åœ¨è¿™é‡Œç®—äº†éªŒè¯ lossã€æŒ‡æ ‡ï¼Œå¹¶ `self.log_dict({...})`ã€‚

**pl.LightningDataModuleï¼ˆDataloaderï¼‰**

* setup()
* train_dataloader()
* val_dataloader()



## training step

```
def training_step(self, batch, batch_idx): # automatically processed 
        loss_dict = {}
        pred_traj_point, _, _ = self.parking_model(batch)

        train_loss = self.traj_point_loss_func(pred_traj_point, batch)        

        loss_dict.update({"train_loss": train_loss})

        self.log_dict(loss_dict)

        return train_loss
```

å¯¹batchè¿›è¡Œæ¨ç†ï¼Œè¾“å‡ºè½¨è¿¹

ä¸çœŸå€¼è®¡ç®—lossï¼Œè¿”å›loss


è¾“å…¥:  [BOS, 5, 9, 4, 2]  # L-1 ä¸ªtoken

è¾“å‡º:  [p(5|BOS), p(9|BOS,5), p(4|BOS,5,9), p(2|BOS,5,9,4), p(EOS|BOS,5,9,4,2)]

GT:    [   5   ,     9     ,    4         ,   2           ,       EOS          ]

```
pred = pred[:, :-1, :]   #å› ä¸ºæœ€åä¸€ä¸ªæ²¡æœ‰gt

gt   = data[:, 1:-1]  
```






### æ•°æ®å¤„ç†æµç¨‹å›¾
```
1. åˆå§‹åŒ– ParkingDataModuleReal(config, is_train)
   â””â”€ è®¾å®šé…ç½®ã€BOS/EOS/PAD tokenã€ç›¸æœºæ ‡ç­¾ç­‰
   â””â”€ è°ƒç”¨ create_gt_data()
2. create_gt_data() æ„å»ºè®­ç»ƒæ•°æ®ç¼“å­˜
   â”œâ”€ è°ƒç”¨ get_all_tasks()
   â”‚   â””â”€ æ ¹æ® is_train å†³å®šä½¿ç”¨ training_dir / validation_dir
   â”‚   â””â”€ éå†ç›®å½•ï¼Œæ”¶é›†æ‰€æœ‰ä»»åŠ¡è·¯å¾„ task_path
   â”œâ”€ éå†æ‰€æœ‰ task_path:
   â”‚   â”œâ”€ åˆå§‹åŒ– CameraInfoParser å’Œ TrajectoryInfoParser
   â”‚   â”œâ”€ è·å–ç›¸æœºå†…å‚ + å¤–å‚ â†’ intrinsic / extrinsic
   â”‚   â””â”€ éå†æ¯ä¸ªæ—¶é—´å¸§ï¼ˆego_indexï¼‰:
   â”‚       â”œâ”€ ego pose â† world åæ ‡ç³»ä¸‹
   â”‚       â”œâ”€ è®¡ç®— world2ego_mat â† pose çš„é€†å˜æ¢
   â”‚       â”œâ”€ create_predict_point_gt()
   â”‚       â”‚   â”œâ”€ è·å–å¤šä¸ª future trajectory poseï¼ˆä¸–ç•Œåæ ‡ï¼‰
   â”‚       â”‚   â”œâ”€ è½¬ä¸º ego åæ ‡ç³»
   â”‚       â”‚   â”œâ”€ ç¼–ç ä¸º token + pad
   â”‚       â”œâ”€ create_parking_goal_gt()
   â”‚       â”‚   â”œâ”€ æ¨¡ç³Šç›®æ ‡ç‚¹ï¼ˆéšæœºï¼‰+ ç²¾ç¡®ç›®æ ‡ç‚¹ï¼ˆæœ€ç»ˆï¼‰
   â”‚       â”‚   â”œâ”€ è½¬ä¸º ego åæ ‡
   â”‚       â”œâ”€ create_image_path_gt()
   â”‚       â”‚   â””â”€ æ„é€ å›¾åƒè·¯å¾„å­—å…¸ï¼š{image_tag: path}
   â”‚       â””â”€ ä¿å­˜æ‰€æœ‰å›¾åƒè·¯å¾„ã€ä½å§¿ã€tokenã€ç›®æ ‡ç‚¹ä¿¡æ¯
   â””â”€ è°ƒç”¨ format_transform() â†’ æ‰€æœ‰ list â†’ numpy æ ¼å¼ç¼“å­˜
3. __getitem__(index)
   â”œâ”€ è°ƒç”¨ process_camera(index)
   â”‚   â”œâ”€ åŠ è½½ 4 å¼ å›¾åƒï¼ˆè·¯å¾„æ¥è‡ª self.images[image_tag]ï¼‰
   â”‚   â”œâ”€ resize â†’ å½’ä¸€åŒ– â†’ æ‹¼æ¥æˆä¸€ä¸ª tensorï¼ˆ[4C,H,W]ï¼‰
   â”‚   â”œâ”€ ç›¸æœºå†…å‚å’Œå¤–å‚ä¹Ÿè½¬ä¸º tensor å¹¶æ‹¼æ¥
   â””â”€ è¿”å›å­—å…¸ï¼š
       {
         "image": å›¾åƒæ‹¼æ¥ Tensor,
         "intrinsics": ç›¸æœºå†…å‚ Tensor,
         "extrinsics": ç›¸æœºå¤–å‚ Tensor,
         "gt_traj_point": å¤šæ­¥è½¨è¿¹ç‚¹ï¼ˆæµ®ç‚¹åæ ‡ï¼‰,
         "gt_traj_point_token": å¤šæ­¥ token ç¼–ç , 
         "target_point": ç²¾ç¡®ç›®æ ‡ç‚¹,
         "fuzzy_target_point": æ¨¡ç³Šç›®æ ‡ç‚¹
       }
4. DataLoader(batch_size, shuffle, num_workers)
   â””â”€ è‡ªåŠ¨è°ƒç”¨ __getitem__() å¹¶æ‰“åŒ…ä¸º batchï¼Œé€å…¥æ¨¡å‹
5. æ¨¡å‹è®­ç»ƒæ¥æ”¶çš„ batch æ•°æ®ï¼š
   â”œâ”€ image: Tensor[B, C*4, H, W]
   â”œâ”€ gt_traj_point: Tensor[B, N*2]
   â”œâ”€ gt_traj_point_token: Tensor[B, token_len]
   â”œâ”€ target_point / fuzzy_target_point: Tensor[B, 2]
   â”œâ”€ intrinsics / extrinsics: Tensor[B, ...]

```

## Data

``` 
batch = next(iter(train_loader))
```

å–å‡ºç¬¬ä¸€ä¸ª batchï¼Œå¹¶æ‰“å°å‡ºç»“æ„

```
  'image': Tensor(shape=(1,4,3,256,256)),
  'extrinsics': Tensor(shape=(1,4,4,4)),
  'intrinsics': Tensor(shape=(1,4,3,3)),
  'target_point': Tensor(shape=(1,2)),
  'gt_traj_point': Tensor(shape=(1,60)),
  'gt_traj_point_token': Tensor(shape=(1,63)),
  'fuzzy_target_point': Tensor(shape=(1,2)),
```

**image**

- shape `(B, C_cams, C_img, H, W)` = `(1, 4, 3, 256, 256)`
- è¿™é‡Œ `B=1`ï¼Œ`4` æ˜¯å››è·¯æ‘„åƒå¤´ï¼ˆfront/left/right/rearï¼‰ï¼Œæ¯è·¯ `3` é€šé“ï¼ˆRGBï¼‰ï¼Œåˆ†è¾¨ç‡ `256Ã—256`ã€‚

**extrinsics**

- shape `(1, 4, 4, 4)`
- å››è·¯æ‘„åƒå¤´çš„ **4Ã—4 é½æ¬¡å¤–å‚çŸ©é˜µ**ï¼Œç¬¬ä¸€ä¸ªç»´åº¦è¿˜æ˜¯ batchã€‚

**intrinsics**

- shape `(1, 4, 3, 3)`
- å››è·¯æ‘„åƒå¤´çš„ **3Ã—3 å†…å‚çŸ©é˜µ**ã€‚

**target_point**

- shape `(1, 2)`
- å½“å‰å¸§çš„ **ç²¾ç¡®åœè½¦ç›®æ ‡ç‚¹**ï¼Œæ ¼å¼ `[x, y]`ã€‚

**gt_traj_point**

- shape `(1, 60)`
- æœªæ¥ `autoregressive_points * item_number` ä¸ªç‚¹æ‹¼æˆçš„å›å½’åæ ‡å‘é‡ï¼ˆå¦‚ 30Ã—2 = 60ï¼‰ã€‚

**gt_traj_point_token**

- shape `(1, 63)`
- åŒæ ·é•¿åº¦çš„ token åºåˆ—ï¼ˆå« BOS/EOS/PADï¼‰ï¼Œé•¿åº¦ = `60 + append_token(3)`ã€‚

**fuzzy_target_point**

- shape `(1, 2)`
- æ¨¡ç³Šåœè½¦ç›®æ ‡ç‚¹ `[x, y]`ã€‚



# Tokenize

å°†è¿ç»­çš„è½¨è¿¹ç‚¹åæ ‡target in egoï¼ˆå¦‚ `(x, y)`ï¼‰æ˜ å°„ä¸ºç¦»æ•£çš„æ•´æ•° Tokenã€‚

```
x_normalize = (x + xy_max) / (2 * xy_max)# å°†æµ®ç‚¹åæ ‡å½’ä¸€åŒ–
y_normalize = (y + xy_max) / (2 * xy_max)

return [int(x_normalize * valid_token), int(y_normalize * valid_token), int(progress_normalize * valid_token)]#ç”Ÿæˆæ•´æ•° Token
```

valid_token:1200

xy_max:15m

1.25cmåˆ†åº¦




## Target encoder

```
bev_target = self.get_target_bev(target_point, mode=mode)
```

è®¡ç®— BEV å›¾åƒå¤§å° h,w -> åˆå§‹åŒ–ç©ºç™½çƒ­åŠ›å›¾ (B,1,h,w)  -> æŠŠåŸç‚¹ï¼ˆè½¦å¤´ï¼‰æ”¾åˆ° BEV å›¾ä¸­å¿ƒ ->é™¤ä»¥åˆ†è¾¨ç‡ `res` æŠŠç±³å•ä½è½¬æ¢æˆç½‘æ ¼å•ä½  -> è®­ç»ƒæ—¶å¯åŠ éšæœºåç§»ï¼ˆæ•°æ®å¢å¼ºï¼‰->  å¯¹æ¯ä¸ªæ ·æœ¬ï¼Œåœ¨ä»¥ `(row,col)` ä¸ºä¸­å¿ƒã€è¾¹é•¿ `2r+1` çš„å°æ–¹å—åŒºåŸŸå†…ç½® `1`ï¼Œå…¶ä½™ä¿æŒ `0`ã€‚

```
bev_target_encoder = self.target_res_encoder(bev_target, flatten=False)
```

## BEV Query 

##### å°†ä¸¤ä¸ª BEV ç‰¹å¾è¿›è¡Œ Transformer èåˆ

``` bev_feature = self.get_feature_fusion(bev_target_encoder, bev_camera_encoder)```

å³

```bev_feature = self.bev_query(bev_target_encoder, bev_camera_encoder)```



```bev_feature = self.tf_query(tgt_feature, memory=img_feature)  # Transformer èåˆ```

æ‰§è¡Œäº†ï¼š

**è‡ªæ³¨æ„åŠ›ï¼ˆSelf-Attentionï¼‰**

- è®©æŸ¥è¯¢è‡ªå·±å†…éƒ¨äº’ç›¸â€œçœ‹â€ä¸€éï¼Œå­¦ä¹ åºåˆ—å†…éƒ¨çš„ä¾èµ–ã€‚

**è·¨æºæ³¨æ„åŠ›ï¼ˆCross-Attentionï¼‰**

- æŠŠ `img_feature`ï¼ˆç›¸æœº BEV æµç¨‹ç¼–ç çš„è¯­ä¹‰ç©ºé—´ä¿¡æ¯ï¼‰æ³¨å…¥åˆ° `tgt_feature`ï¼ˆç›®æ ‡çƒ­åŠ›å›¾ç¼–ç ï¼‰çš„è¡¨ç¤ºé‡Œã€‚

**å‰é¦ˆç½‘ç»œï¼ˆFeed-Forward Networkï¼‰**

- æ“ä½œï¼šè·¨æ³¨æ„åŠ›åçš„æ¯ä¸ªä½ç½®å†è¿‡ä¸¤å±‚å…¨è¿æ¥+æ¿€æ´» (`Linear â†’ GELU/ReLU â†’ Linear`)ï¼Œå¢å¼ºéçº¿æ€§è¡¨è¾¾ã€‚

**æ®‹å·® + LayerNorm**

- æ¯ä¸ªå­å±‚ï¼ˆè‡ªæ³¨æ„åŠ›ã€è·¨æ³¨æ„åŠ›ã€å‰é¦ˆï¼‰éƒ½æœ‰ **æ®‹å·®è¿æ¥**ï¼šè¾“å‡º = å­å±‚(è¾“å…¥) + è¾“å…¥
- ç´§è·Ÿä¸€ä¸ª **LayerNorm**ï¼Œä¿æŒæ¢¯åº¦ç¨³å®šã€‚

**å¤šå±‚å †å **

- `num_layers=self.cfg.query_en_layers`ï¼Œå°±é‡å¤ä¸Šé¢çš„æµç¨‹è‹¥å¹²æ¬¡ï¼Œè®©èåˆæ›´æ·±ã€æ›´çµæ´»ã€‚





tgt_feature.shape = (B, C, H, W)

â€‹					|

â†’ view() ä¸º (B, C, H*W)

â€‹					|

â†’ permute â†’ (B, HW, C)

â€‹					|

+self.pos_embed åŠ ä½ç½®ç¼–ç 

â€‹					|

self.tf_query(tgt_feature, memory=img_feature)   è®© `target BEV` å¯¹ `camera BEV` åšå¤šå¤´æ³¨æ„åŠ›

â€‹					|

(B, HW, C) â†’ permute â†’ reshape â†’ (B, C, H, W)



### Trajectory Decoder

```
def forward(self, encoder_out, tgt):
# train: (bev_feature, data['gt_traj_point_token'].cuda())

tgt = tgt[:, :-1]  # å»æ‰æœ€åä¸€ä¸ª tokenï¼ˆå¦‚ EOSï¼‰ï¼Œåš teacher forcing
tgt_mask, tgt_padding_mask = self.create_mask(tgt)

tgt_embedding = self.embedding(tgt)

tgt_embedding = self.pos_drop(tgt_embedding + self.pos_embed)    **å…ˆåšembedding**

pred_traj_points = self.decoder(encoder_out, tgt_embedding, tgt_mask, tgt_padding_mask)
```



å¯¹ `tgt_embedding` åšï¼š

1. è‡ªæ³¨æ„åŠ›ï¼ˆmasked self-attentionï¼‰
2. å’Œ `encoder_out` åšäº¤å‰æ³¨æ„åŠ›ï¼ˆcross-attentionï¼‰
3. å‰é¦ˆç½‘ç»œï¼ˆMLPï¼‰
4. æ¯ä¸€å±‚æœ‰æ®‹å·®è¿æ¥å’Œ LayerNorm



**Teacher Forcing** æ˜¯è®­ç»ƒåºåˆ—æ¨¡å‹æ—¶ç”¨çœŸå® token ä½œä¸º decoder çš„è¾“å…¥ï¼ˆè€Œä¸æ˜¯è‡ªå·±é¢„æµ‹çš„ï¼‰ï¼Œæé«˜è®­ç»ƒç¨³å®šæ€§ã€‚

**å‡è®¾`gt_traj_point_token` æ˜¯ï¼š**

```
[BOS, token1, token2, ..., tokenN, EOS]
```

ä½ è¾“å…¥ decoder çš„æ˜¯ `tgt[:, :-1] = [BOS, token1, ..., tokenN]`ï¼ˆç”¨ä½œæ¯ä¸€æ­¥ decoder è¾“å…¥ï¼‰

ä½ ç›‘ç£çš„æ˜¯ `tgt[:, 1:] = [token1, ..., tokenN, EOS]`ï¼ˆç”¨ä½œç›®æ ‡è¾“å‡ºï¼‰åš `CrossEntropyLoss`

**æ¨ç†æ—¶ä¸èƒ½ç”¨ Teacher Forcing**

> åœ¨ `predict()` é˜¶æ®µï¼Œæ˜¯ auto-regressive æ¨ç†ï¼Œ**åªèƒ½ç”¨æ¨¡å‹è‡ªå·±å‰ä¸€æ­¥çš„é¢„æµ‹ä½œä¸ºå½“å‰è¾“å…¥**ã€‚

ä½ ä»£ç ä¸­ä½“ç°ï¼š

```
pred_traj_points = self.output(pred_traj_points)[:, length - offset, :]
...
pred_traj_points = torch.softmax(...).argmax(...)  # è‡ªå·±é€‰ token
...
tgt = torch.cat([tgt, pred_traj_points], dim=1)  
```

### Masking

```
tgt_mask, tgt_padding_mask = self.create_mask(tgt)
```

å‘Šè¯‰ Transformer åœ¨ attention æ—¶å¿½ç•¥ PAD token çš„å½±å“ï¼ˆattention score ä¸è®¡ç®—ï¼‰

```
tgt_padding_mask = [[False, False, True, True]]
```

å‘Šè¯‰ Transformer åœ¨ attention æ—¶å¿½ç•¥ PAD token çš„å½±å“ï¼ˆattention score ä¸è®¡ç®—ï¼‰



**Embedding**

embedding æ˜¯**ä¸€ä¸ªå¯å­¦ä¹ çš„ã€éšæœºåˆå§‹åŒ–çš„æŸ¥è¡¨å¼ embedding å±‚**ã€‚ä¸æ˜¯é¢„è®­ç»ƒçš„ word embeddingã€ä¹Ÿä¸æ˜¯ positional embeddingã€ä¹Ÿä¸æ˜¯ learned codebook embedding

```
self.embedding = nn.Embedding(self.cfg.token_nums + self.cfg.append_token, self.cfg.tf_de_dim)
```

**`nn.Embedding(num_embeddings, embedding_dim)` çš„å«ä¹‰ï¼š**

| å‚æ•°å           | å«ä¹‰                                                         |
| ---------------- | ------------------------------------------------------------ |
| `num_embeddings` | ä½ å¸Œæœ›èƒ½åµŒå…¥çš„ token æ€»æ•°ï¼ˆå³è¯è¡¨å¤§å°ï¼‰                      |
| `embedding_dim`  | æ¯ä¸ª token å¯¹åº”çš„åµŒå…¥å‘é‡ç»´åº¦ï¼ˆå³è¯å‘é‡ç»´åº¦ï¼‰                |
| åˆå§‹åŒ–           | é»˜è®¤æ˜¯ `torch.nn.init.normal_()` åˆå§‹åŒ–ä¸ºæ­£æ€åˆ†å¸ƒï¼ˆæˆ–å¯æ‰‹åŠ¨ä¿®æ”¹ï¼‰ |
| å­¦ä¹ æ–¹å¼         | å‚ä¸åå‘ä¼ æ’­ï¼Œ**å¯è®­ç»ƒ**                                     |

**Pose embedding**

```
self.pos_embed = nn.Parameter(torch.randn(1, max_len, hidden_dim) * 0.02)
```

torch.randn(1, L, D) å¯¹æ‰€æœ‰å…ƒç´ ä¹˜ä»¥ 0.02ï¼Œé€šå¸¸ç”¨äºç¼©å°åˆå§‹å€¼èŒƒå›´ï¼Œä½¿è®­ç»ƒæ›´ç¨³å®šã€‚

> shape ä¸º `[1, L, D]` çš„å¼ é‡ä¼šè‡ªåŠ¨åœ¨ batch ç»´åº¦ä¸Šå¹¿æ’­æˆ `[B, L, D]`ï¼Œç„¶åä¸ token embedding å¯¹åº”ä½ç½®å…ƒç´ ç›¸åŠ ã€‚

**æ³¨æ„ï¼š**

token embedding ç”¨ nn.Embedding æ˜¯å› ä¸ºå®ƒæœ¬è´¨æ˜¯â€œæŸ¥è¡¨â€ï¼ˆtoken id â†’ å‘é‡ï¼‰ï¼Œè€Œ position embedding ç”¨ nn.Parameter æ˜¯å› ä¸ºå®ƒæ˜¯ä¸€ä¸ªå›ºå®š shape çš„å¯è®­ç»ƒçŸ©é˜µï¼Œç›´æ¥ç›¸åŠ ï¼Œæ— éœ€æŸ¥è¡¨ã€‚



## Transformer Decoder

PyTorch çš„ `TransformerDecoder` æ¥æ”¶çš„ç»´åº¦è¦æ±‚æ˜¯ `[seq_len, batch, dim]`ï¼Œæ‰€ä»¥å…ˆè½¬ç½®ï¼š

```
encoder_out = encoder_out.transpose(0, 1) 
tgt_embedding = tgt_embedding.transpose(0, 1)
```

ç„¶ååšdecoder

```
pred_traj_points = self.tf_decoder(tgt=tgt_embedding,
                                        memory=encoder_out,
                                        tgt_mask=tgt_mask,
                                        tgt_key_padding_mask=tgt_padding_mask)
```

å…¶ä¸­

```
self.tf_decoder = nn.TransformerDecoder(tf_layer, num_layers=self.cfg.tf_de_layers)
```

#### å¯¹ tgt_embedding è¿›è¡Œï¼š

1. Multi-head **self-attention**ï¼ˆå¸¦ causal maskï¼‰
2. Multi-head **cross-attention** with **encoder_out**(å›¾åƒ)
3. FeedForward + LayerNorm ç­‰æ ‡å‡†æ¨¡å—
4. å¤šå±‚å †å ï¼ˆ`num_layers` ç”± config æ§åˆ¶ï¼‰

è¾“å‡º shape åŒ `tgt_embedding`ï¼š`[L, B, D]`



## ğŸ” Learnable Positional Embedding vs Fixed

| å¯¹æ¯”é¡¹               | Learnable PosEmbed                         | Sinusoidal PosEmbed (Fixed) |
| -------------------- | ------------------------------------------ | --------------------------- |
| æ˜¯å¦å¯è®­ç»ƒ           | âœ… æ˜¯                                       | âŒ å¦                        |
| è¡¨è¾¾èƒ½åŠ›             | é«˜ï¼Œè‡ªç”±åº¦å¤§                               | æœ‰ä¸€å®šè§„å¾‹æ€§ï¼Œé€‚åˆæ³›åŒ–      |
| èƒ½å¦å¤–æ¨é•¿åºåˆ—       | ä¸ä¸€å®šå¥½ï¼ˆå—é™äºè®­ç»ƒæ—¶é•¿åº¦ï¼‰               | âœ… å¯å¤–æ¨ï¼ˆå› å‡½æ•°æœ‰å‘¨æœŸæ€§ï¼‰  |
| ç”¨äº NLP/BERT        | âœ… å¸¸è§äº BERTã€GPT                         | æ›¾åœ¨åŸå§‹ Transformer ä½¿ç”¨   |
| ç”¨äº Trajectory Task | âœ… å¸¸è§ï¼ˆå› ä¸ºè½¨è¿¹é•¿åº¦å›ºå®šï¼Œä¸è¦æ±‚æ³›åŒ–é•¿åº¦ï¼‰ | å¯é€‰                        |

# è®­ç»ƒç»“æ„

åœ¨**train.py**ä¸­ï¼Œæœ‰

```
ParkingTrainingModelModule = get_parking_model(data_mode=config_obj.data_mode, run_mode="train") 
```

åœ¨**model_interface.py**ä¸­ï¼Œæœ‰

```
model_class = ParkingTrainingModuleReal
```

åœ¨**trainer_real.py**ä¸­ï¼Œæœ‰ 

```
class ParkingTrainingModuleReal(pl.LightningModule):
    self.parking_model = ParkingModelReal(self.cfg)
```

åœ¨**parking_model_real.py**ä¸­ï¼Œå®ä¾‹åŒ–äº†ä½¿ç”¨äº†åŠŸèƒ½

```
class ParkingModelReal(nn.Module):
    self.lss_bev_model = LssBevModel(self.cfg)
    self.image_res_encoder = BevEncoder(in_channel=self.cfg.bev_encoder_in_channel)

    # Target Encoder
    self.target_res_encoder = BevEncoder(in_channel=1)

    # BEV Query
    self.bev_query = BevQuery(self.cfg)

    # Trajectory Decoder
    self.trajectory_decoder = self.get_trajectory_decoder()
```



## ä¼˜åŒ–

**1.è¿‡æ‹Ÿåˆ**

åšæ•°æ®å¢å¼ºï¼ˆåŠ å™ªï¼Œæˆªæ–­ï¼Œå¤šåœºæ™¯ï¼‰

**2.åœ¨é€¼è¿‘è½¦ä½æ—¶ï¼Œé¢„æµ‹è½¨è¿¹åç¦»**

å¯¹ target é€šé“åšé«˜æ–¯åˆ†å¸ƒå¤„ç†ï¼Œ BEV ç©ºé—´å¯¹â€œåœè½¦ç›®æ ‡ç‚¹â€ç”Ÿæˆçƒ­å›¾ï¼Œä½œä¸º Encoder çš„ Queryã€‚ç”¨ 2D é«˜æ–¯è®©ç½‘ç»œå­¦ä¹ ä¸ä»…çŸ¥é“â€œåœ¨å“ªå„¿â€ï¼Œè¿˜çŸ¥é“â€œç½®ä¿¡åº¦éšç€è·ç¦»è¡°å‡â€çš„åˆ†å¸ƒã€‚

æ•ˆæœï¼šæœ‰åŠ©äºç½‘ç»œå­¦åˆ°æ›´ç²¾ç»†çš„ä¾§å‘å®šä½



## ä¸ºä»€ä¹ˆç”¨CEï¼Ÿ

1. ä¸ Transformer è‡ªå›å½’æ¡†æ¶å¤©ç„¶å¥‘åˆ

â€‹		Transformer Decoder åŸç”Ÿå°±æ˜¯**ç¦»æ•£ token çš„åºåˆ—åˆ°åºåˆ—å»ºæ¨¡**

2. åœè½¦è½¨è¿¹å¾€å¾€å­˜åœ¨å¤šç§å¯è¡Œè·¯å¾„ï¼ˆå¤šæ¨¡æ€ï¼‰ï¼›å›å½’æŸå¤±ï¼ˆMSEï¼‰å‡è®¾è¾“å‡ºæ˜¯å•å³°é«˜æ–¯ï¼Œå®¹æ˜“å¹³å‡åŒ–å¤šç§è§£ï¼Œç»“æœè½åœ¨â€œå¤šç§è½¨è¿¹ä¸­é—´â€çš„ä¸åˆç†ä½ç½®ã€‚

3. å›å½’ Lâ‚‚ Loss å¯¹äºå°ºåº¦ã€å•ä½éå¸¸æ•æ„Ÿï¼Œéœ€è¦ç²¾å¿ƒè°ƒæ•´ç½‘ç»œçš„è¾“å‡ºèŒƒå›´ã€å­¦ä¹ ç‡ï¼›CE Loss åšåˆ†ç±»ï¼Œlogits â†’ softmax â†’ log æ¦‚ç‡ï¼Œä¸€èˆ¬æ›´å®¹æ˜“æ”¶æ•›ã€‚
4. BEV ç©ºé—´é‡åŒ–æˆå›ºå®šç½‘æ ¼ï¼Œtoken æœ¬èº«å°±ä»£è¡¨æŸä¸ªæ ¼å­ç´¢å¼•ï¼›ç›´æ¥å›å½’åˆ°è¿ç»­åæ ‡å°±ç»•è¿‡äº†ç½‘æ ¼ç»“æ„ï¼Œä¸å®¹æ˜“å¯¹é½ BEV ç‰¹å¾å’Œæ¨¡å‹çš„è¾“å‡ºã€‚

CE LOSSï¼Ÿ

l2 distance

hausdorff distance

